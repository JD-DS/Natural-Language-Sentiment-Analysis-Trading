{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8dffbf49-03ea-4fe3-b229-d2dbc55e4fe8",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Natural Language Processing:\n",
    "        Momentum Trading Derivatives Based On Sentiment Analyis\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: show\n",
    "jupyter: python3\n",
    "execute: \n",
    "  enabled: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd41da0-b71d-4943-a920-ca8dc3244fe4",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:red\"># **Project In Progress: Updated 9/18/2022**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940dd724-39ed-47b4-814c-a602302f7a19",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710af5f8-cb28-49a3-a8af-dc855fad8835",
   "metadata": {},
   "source": [
    "\n",
    "## Motivation:\n",
    "\n",
    "Social media subgroups that focus on trading tend to be filled with poor analysis and a lack of due diligince. More sophisticated investors and traders tend to create groups on forumns and websites where there is a barrier to entry in order to ensure quality in discusion and analysis. Even with this reality, large sub groups on social media sites like reddit's wall street bets have, in the past, been able to move prices in the equity markets based on the sheer number of participants involnved in group think on the website. If we can gain insight using natural language processing to gauge sentiment on forums like this one, we may then be able to identify mis-priced derivatves based on our price and volume projections coupled with implied and historical volatitly on the contracts themselves. If we beleive that the sentiment will influence future prices a certain way, we may be able to momentum trade the derivatives contracts, opening positions on contracts that we belive to be mispriced based on our assumtions and projections of future volatility. \n",
    "\n",
    "This introduction will be updated as the project continues accordingly:\n",
    "\n",
    "1. Sentiment analysis of stock market related reddit forumns\n",
    "2. Derivatives pricing math (framework for pricing) and assumptions needed to determine 'mis-pricing'\n",
    "3. APIs used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cdf67e-4722-4037-bf85-b2f2e0506098",
   "metadata": {},
   "source": [
    "# Part 1: Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46b341-2db0-48dc-adab-3ec466b22532",
   "metadata": {},
   "source": [
    "## Using the Reddit API to develope a sentiment analysis dashboard - Tickers mentioned and pos / neg sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b5fe7c-0a7a-4563-9f3c-1f11210beaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laod libraries and packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import dotenv\n",
    "import sys\n",
    "from IPython import display\n",
    "import math\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid', context='talk', palette='Dark2')\n",
    "sys.tracebacklimit = 0 # turn off the error tracebacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d64724-241c-4756-8ebf-6e70614bdfd9",
   "metadata": {},
   "source": [
    "## Part 1a:\n",
    "### Connect to reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba98b5db-7bdc-4f73-bb30-61ea0639de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API request relevent information \n",
    "\n",
    "# Create variables for keys and access token from .env file\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "secret = os.getenv('client_secret')\n",
    "\n",
    "client = os.getenv('client_id')\n",
    "\n",
    "user = os.getenv('user_agent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924a1f6f-0d4f-4225-bb2b-35f3a7a4a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request reddit API using PRAW \n",
    "\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id = client,\n",
    "                     client_secret = secret,\n",
    "                     user_agent = user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b580a-1632-48cf-92e6-649a9d14a16d",
   "metadata": {},
   "source": [
    "## Part 1b:\n",
    "### Headlines: Gather headlines from stock market related subreddits - 'Wallstreetbets'.'TheWallStreet', 'TradeVol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6200d2d6-9450-4830-8ccb-ac1fcdf1132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923 headlines found from wallstreetbets\n"
     ]
    }
   ],
   "source": [
    "# Create empty set to hold post headlines, so as not to create duplicates\n",
    "\n",
    "headlines_wsb = set()\n",
    "\n",
    "# Iterate through Wall Street Bets for headlines \n",
    "\n",
    "for submission in reddit.subreddit('wallstreetbets').new(limit=None):\n",
    "    headlines_wsb.add(submission.title)\n",
    "    display.clear_output()\n",
    "    print(len(headlines_wsb),'headlines found from wallstreetbets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a7ba02-5730-49af-ae47-f8f2f094aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 headlines found from TradeVOl\n"
     ]
    }
   ],
   "source": [
    "# Repeat for r/TradeVol\n",
    "\n",
    "headlines_vol = set()\n",
    "\n",
    "# Iterate through  for headlines \n",
    "\n",
    "for submission in reddit.subreddit('TradeVol').new(limit=None):\n",
    "    headlines_vol.add(submission.title)\n",
    "    display.clear_output()\n",
    "    print(len(headlines_vol),'headlines found from TradeVOl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff61665-57d2-4345-91c7-5bf4405aca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 headlines found from TheWallStreet\n"
     ]
    }
   ],
   "source": [
    "# Repeat for r/TheWallStreet\n",
    "\n",
    "headlines_wstreet = set()\n",
    "\n",
    "# Iterate through  for headlines \n",
    "\n",
    "for submission in reddit.subreddit('TheWallStreet').new(limit=None):\n",
    "    headlines_wstreet.add(submission.title)\n",
    "    display.clear_output()\n",
    "    print(len(headlines_wstreet),'headlines found from TheWallStreet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e4c765-0cc8-40a2-927f-6232c912725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download vader lexicon package from natural language toolkit used below\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e502d1-48ee-4d42-8844-f96b21dd465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update vader lexicon dictionary with new words we want to look for\n",
    "# plus their sentiment scores\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "new_words = {\n",
    "    'call': 3.0,\n",
    "    'put': -3.0,                                                      # this step is important, more to come\n",
    "}\n",
    "\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "\n",
    "SIA.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3ddda-6e10-4c7a-8a2f-aae5d7801e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694eadb-b553-4802-831e-16a659e325a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b0c1320-7b6c-444a-9357-c143d3334f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'compound': 0.4588,\n",
      "  'headline': '*insert favorite stock here*',\n",
      "  'neg': 0.0,\n",
      "  'neu': 0.5,\n",
      "  'pos': 0.5},\n",
      " {'compound': 0.0,\n",
      "  'headline': 'ES Technical Analysis by Adam Mancini',\n",
      "  'neg': 0.0,\n",
      "  'neu': 1.0,\n",
      "  'pos': 0.0},\n",
      " {'compound': 0.0, 'headline': 'Live look at my portfolio', 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Intensity Analyzer (SIA) - WSB\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "results_WSB = []\n",
    "\n",
    "for line in headlines_wsb:\n",
    "    pol_score = sia.polarity_scores(line)\n",
    "    pol_score['headline'] = line\n",
    "    results_WSB.append(pol_score)\n",
    "\n",
    "pprint(results_WSB[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed518af-851b-4ded-91bc-3b0ed0ff96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Intensity Analyzer (SIA) - TradeVOl\n",
    "\n",
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "results_VOL = []\n",
    "\n",
    "for line in headlines_vol:\n",
    "    pol_score = sia.polarity_scores(line)\n",
    "    pol_score['headline'] = line\n",
    "    results_VOL.append(pol_score)\n",
    "\n",
    "# pprint(results_VOL[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033d9a36-681f-4da4-8b3a-cedd5fb917a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Intensity Analyzer (SIA) - TheWallStreet\n",
    "\n",
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "results_WST = []\n",
    "\n",
    "for line in headlines_wstreet:\n",
    "    pol_score = sia.polarity_scores(line)\n",
    "    pol_score['headline'] = line\n",
    "    results_WST.append(pol_score)\n",
    "\n",
    "# pprint(results_WST[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec16bc65-49c1-4d7a-9479-49b88cf25c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>*insert favorite stock here*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>ES Technical Analysis by Adam Mancini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Live look at my portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Hedgies rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Thing to Know Today: What CPI revealed about o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neg  neu  pos  compound                                           headline\n",
       "0  0.0  0.5  0.5    0.4588                       *insert favorite stock here*\n",
       "1  0.0  1.0  0.0    0.0000              ES Technical Analysis by Adam Mancini\n",
       "2  0.0  1.0  0.0    0.0000                          Live look at my portfolio\n",
       "3  0.0  1.0  0.0    0.0000                                         Hedgies rn\n",
       "4  0.0  1.0  0.0    0.0000  Thing to Know Today: What CPI revealed about o..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame from the headlines results\n",
    "df_wsb = pd.DataFrame.from_records(results_WSB)         # Compound variable scale from very neg (-1) - very pos (1)\n",
    "df_wsb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400a7e86-9352-498b-8dbe-10cf3b1085bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Daily Discussion - (November 30, 2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Post Market Discussion - (August 31, 2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Deviations for Wednesday, January 5, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nightly Discussion - (January 16, 2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Daily Discussion - (November 25, 2021)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neg  neu  pos  compound                                    headline\n",
       "0  0.0  1.0  0.0       0.0      Daily Discussion - (November 30, 2021)\n",
       "1  0.0  1.0  0.0       0.0  Post Market Discussion - (August 31, 2022)\n",
       "2  0.0  1.0  0.0       0.0   Deviations for Wednesday, January 5, 2021\n",
       "3  0.0  1.0  0.0       0.0     Nightly Discussion - (January 16, 2022)\n",
       "4  0.0  1.0  0.0       0.0      Daily Discussion - (November 25, 2021)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame from the headlines results\n",
    "\n",
    "df_wst = pd.DataFrame.from_records(results_WST)\n",
    "df_wst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60eea2da-85af-45e1-b387-8de433ef5bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>Best broker for shorting UVXY, VXX, and similar?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Volatility Trading Weekly Discussion - March 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Link- VIX The Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.164</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>Most Overlooked Opportunity of 2022 | $VXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Volatility Trading Weekly Discussion - April 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound  \\\n",
       "0  0.000  0.625  0.375    0.6369   \n",
       "1  0.000  1.000  0.000    0.0000   \n",
       "2  0.000  1.000  0.000    0.0000   \n",
       "3  0.164  0.472  0.363    0.3990   \n",
       "4  0.000  1.000  0.000    0.0000   \n",
       "\n",
       "                                            headline  \n",
       "0   Best broker for shorting UVXY, VXX, and similar?  \n",
       "1  Volatility Trading Weekly Discussion - March 2...  \n",
       "2                                Link- VIX The Virus  \n",
       "3         Most Overlooked Opportunity of 2022 | $VXX  \n",
       "4  Volatility Trading Weekly Discussion - April 2...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame from the headlines results\n",
    "df_vol = pd.DataFrame.from_records(results_VOL)\n",
    "df_vol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a79bbb-de67-402f-8c19-243e9c82b490",
   "metadata": {},
   "source": [
    "We can see that the SIA is not performing optimally, we need to parse the hedlines and add words to the vader lexicon dictionary in order to properly identify community slang, and trading terms as either positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c76d5e-9d52-4512-ae26-66959874ab8d",
   "metadata": {},
   "source": [
    "## Part 1c:\n",
    "### Gather comments from certain posts and analyze sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc822d1-8e6e-47ca-8680-90ccb20ac194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48882d8-bc8f-4620-990c-41777639b62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
